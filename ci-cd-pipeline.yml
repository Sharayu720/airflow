name: Deploy Apache Airflow to Test Environment

on:
  push:
    branches:
      - test  # Trigger on push to the 'test' branch

jobs:
  setup:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the code
      - name: Checkout code
        uses: actions/checkout@v2

      # Step 2: Set up Python environment
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m venv airflow_venv
          source airflow_venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Set up Airflow Database (SQLite for testing)
      - name: Set up Airflow Database (SQLite)
        run: |
          source airflow_venv/bin/activate
          export AIRFLOW_HOME=/home/ec2-user/airflow  # Ensure we're using the correct directory path
          airflow db init

      # Step 5: Create Airflow Admin User
      - name: Create Airflow Admin User
        run: |
          source airflow_venv/bin/activate
          airflow users create \
            --username admin \
            --firstname John \
            --lastname Doe \
            --email john.doe@example.com \
            --role Admin \
            --password ${{ secrets.AIRFLOW_ADMIN_PASSWORD }}

      # Step 6: Install and Configure Nginx for Reverse Proxy
      - name: Install and Configure Nginx
        run: |
          sudo apt-get update
          sudo apt-get install -y nginx
          sudo cp nginx.conf /etc/nginx/sites-available/airflow
          sudo ln -s /etc/nginx/sites-available/airflow /etc/nginx/sites-enabled/
          sudo systemctl restart nginx

      # Step 7: Create necessary directories and set permissions
      - name: Set up directories and permissions for Airflow
        run: |
          # Create the necessary directories for Airflow logs
          sudo mkdir -p /home/ec2-user/airflow/logs/scheduler
          sudo mkdir -p /home/ec2-user/airflow/logs/webserver

          # Set the ownership of the Airflow directory to the ec2-user
          sudo chown -R ec2-user:ec2-user /home/ec2-user/airflow

          # Grant full permissions to the logs directory
          sudo chmod -R 777 /home/ec2-user/airflow/logs

      # Step 8: Start Airflow Webserver
      - name: Start Airflow Webserver
        run: |
          source airflow_venv/bin/activate
          nohup airflow webserver -p 8080 &

      # Step 9: Start Airflow Scheduler
      - name: Start Airflow Scheduler
        run: |
          source airflow_venv/bin/activate
          nohup airflow scheduler &

      # Step 10: Upload DAG files to EC2 instance
      - name: Upload DAGs to EC2 instance
        run: |
          # Load the SSH private key from GitHub secrets
          echo "$SSH_PRIVATE_KEY" > /tmp/id_rsa
          chmod 600 /tmp/id_rsa

          # Clone the repository using SSH with the private key
          git clone git@github.com:Sharayu720.git /home/ec2-user/airflow/dags/airflow
          cd /home/ec2-user/airflow/dags/airflow
          git checkout test  # Checkout the 'test' branch

          # Upload DAGs to EC2 instance (Use ec2-user for EC2)
          scp -i /tmp/id_rsa -r ./dags/ ec2-user@<your-ec2-private-ip>:/home/ec2-user/airflow/dags/

      # Step 11: Restart Airflow Services (optional)
      - name: Restart Airflow Services
        run: |
          sudo systemctl restart airflow-webserver
          sudo systemctl restart airflow-scheduler

      # Step 12: Health check (optional)
      - name: Check Airflow Webserver Health
        run: |
          # Wait for the Airflow webserver to start and respond
          echo "Waiting for Airflow Webserver to be ready..."
          for i in {1..10}; do
            if curl --silent --fail http://localhost:8080; then
              echo "Airflow Webserver is up and running!"
              exit 0
            else
              echo "Attempt $i: Airflow Webserver is not ready yet. Retrying in 5 seconds..."
              sleep 5
            fi
          done
          echo "Airflow Webserver is still not ready after 10 attempts."
          exit 1
