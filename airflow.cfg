[core]
# The home folder for Airflow where all configurations and logs are stored.
# Change this to a directory that is writable by the ec2-user
airflow_home = /home/ec2-user/airflow  # Updated to ec2-user's home directory

# The folder where your DAGs are located.
dags_folder = /home/ec2-user/airflow/dags  # Update this to the correct path

# The folder where your Airflow logs are stored.
# Updated to reflect the new airflow_home location.
base_log_folder = /home/ec2-user/airflow/logs  # Updated path

# The location where the SQLite database is used to track tasks and DAG state.
# For production environments, consider using PostgreSQL or MySQL.
sql_alchemy_conn = sqlite:////home/ec2-user/airflow/airflow.db  # Updated to ec2-user's path

# The executor to use for running Airflow tasks. Use LocalExecutor for testing.
executor = LocalExecutor  # You can change to CeleryExecutor if you need distributed execution.

# Default timezone for Airflow UI
default_timezone = utc

[scheduler]
# Scheduler settings
scheduler_task_queued_timeout = 600  # 10 minutes

[webserver]
# Web server settings for the Airflow UI
web_server_port = 8080
web_server_host = 0.0.0.0  # Make the UI accessible externally
authenticate = False  # Change to True if using authentication

[database]
# Database connection settings (use PostgreSQL or MySQL in production)
sql_alchemy_conn = sqlite:////home/ec2-user/airflow/airflow.db  # Updated to ec2-user's path

[dag_processing]
dag_dir_list_interval = 300  # 5 minutes for scanning the DAG folder
dag_processor_timeout = 600  # 10 minutes before a DAG processor terminates

[logging]
# Logging settings
logging_level = INFO
log_format = [%(asctime)s] %(levelname)s - %(message)s
task_log_prefix_template = {{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log
base_log_folder = /home/ec2-user/airflow/logs  # Updated to ec2-user's path

[celery]
# Celery Executor settings (if using Celery, uncomment and set the following):
# celery_broker_url = redis://localhost:6379/0
# celery_result_backend = db+postgresql://username:password@localhost/dbname

[users]
# Airflow user section (configure if using authentication in the Airflow UI)

[secrets]
# Secrets backend configuration (configure if using a secrets manager)
